{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0939c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f6e09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                Will Ì_ b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"E:\\NLP Project\\SMS Spam Collection Dataset\\spam.csv\", encoding = 'ISO-8859-1')\n",
    "df[\"v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83f5dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099f3abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                Will Ì_ b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"v2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654263e0",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d495b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans(\"\", \"\", string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fccf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"v2\"] = df[\"v2\"].map(lambda text : text.translate(translator) if isinstance(text, str) else text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bd45ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point crazy Available only in ...\n",
       "1                                 Ok lar Joking wif u oni\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3             U dun say so early hor U c already then say\n",
       "4       Nah I dont think he goes to usf he lives aroun...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                  Will Ì b going to esplanade fr home\n",
       "5569    Pity  was in mood for that Soany other suggest...\n",
       "5570    The guy did some bitching but I acted like id ...\n",
       "5571                            Rofl Its true to its name\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0348ff1",
   "metadata": {},
   "source": [
    "### tokenixe string/create list of string including punctuation and make lowercase\n",
    "\n",
    "### For example:\n",
    "###    import nltk\n",
    "### nltk.download('punkt')\n",
    "\n",
    "### Define a piece of text\n",
    " text = \"The quick brown fox jumps over the lazy  dog\"\n",
    "\n",
    "### Tokenize the text\n",
    " tokens = nltk.word_tokenize(text)\n",
    "\n",
    "### Print the tokens\n",
    " print(tokens)\n",
    "### Output: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71851166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"v2\"] = df[\"v2\"].map(lambda x : x.lower()).apply(lambda text : word_tokenize(text) if isinstance(text, str) else text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b27a8a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [go, until, jurong, point, crazy, available, o...\n",
       "1                          [ok, lar, joking, wif, u, oni]\n",
       "2       [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
       "3       [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4       [nah, i, dont, think, he, goes, to, usf, he, l...\n",
       "                              ...                        \n",
       "5567    [this, is, the, 2nd, time, we, have, tried, 2,...\n",
       "5568         [will, ì, b, going, to, esplanade, fr, home]\n",
       "5569    [pity, was, in, mood, for, that, soany, other,...\n",
       "5570    [the, guy, did, some, bitching, but, i, acted,...\n",
       "5571                     [rofl, its, true, to, its, name]\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"v2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ebc83",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bdbfca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating stopword object\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0874b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"v2\"] = df[\"v2\"].map(lambda text : [word for word in text if word.lower() not in stop_words] if isinstance(text, list) else text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "454269b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [go, jurong, point, crazy, available, bugis, n...\n",
       "1                          [ok, lar, joking, wif, u, oni]\n",
       "2       [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
       "3           [u, dun, say, early, hor, u, c, already, say]\n",
       "4       [nah, dont, think, goes, usf, lives, around, t...\n",
       "                              ...                        \n",
       "5567    [2nd, time, tried, 2, contact, u, u, å£750, po...\n",
       "5568                   [ì, b, going, esplanade, fr, home]\n",
       "5569                     [pity, mood, soany, suggestions]\n",
       "5570    [guy, bitching, acted, like, id, interested, b...\n",
       "5571                                   [rofl, true, name]\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa348041",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join tokenize words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb9d95",
   "metadata": {},
   "source": [
    "### The Porter stemming algorithm is a widely used algorithm for stemming in natural language processing (NLP). The algorithm reduces words to their base or root form, by removing suffixes from the words. The nltk library in Python provides an implementation of the Porter stemming algorithm through the PorterStemmer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2eb9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb820853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"v2\"] = df[\"v2\"].apply(lambda text: \" \".join([ps.stem(word) for word in text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f6588fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go jurong point crazi avail bugi n great world...\n",
       "1                                   ok lar joke wif u oni\n",
       "2       free entri 2 wkli comp win fa cup final tkt 21...\n",
       "3                     u dun say earli hor u c alreadi say\n",
       "4               nah dont think goe usf live around though\n",
       "                              ...                        \n",
       "5567    2nd time tri 2 contact u u å£750 pound prize 2...\n",
       "5568                              ì b go esplanad fr home\n",
       "5569                              piti mood soani suggest\n",
       "5570    guy bitch act like id interest buy someth els ...\n",
       "5571                                       rofl true name\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"v2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845907df",
   "metadata": {},
   "source": [
    "### TF-IDF stands for Term Frequency-Inverse Document Frequency. It is a widely used technique in natural language processing (NLP) for converting textual data into numerical form.\n",
    "\n",
    "The basic idea behind TF-IDF is to give weight to words that are more important in a given document and less important in the corpus as a whole. This is done by calculating two measures: term frequency (TF) and inverse document frequency (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a6ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cd34d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tfidf.fit_transform(df[\"v2\"].values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f42ac34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "570d9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4103a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "        ... \n",
       "5567    spam\n",
       "5568     ham\n",
       "5569     ham\n",
       "5570     ham\n",
       "5571     ham\n",
       "Name: v1, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a4a8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c00bb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha = 1.0, fit_prior = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2063cc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "032dbdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68c32f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9641255605381166"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ca15d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.96      0.98      1011\n",
      "        spam       0.72      1.00      0.84       104\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.86      0.98      0.91      1115\n",
      "weighted avg       0.97      0.96      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cf23679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d81d527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc0b297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = model_2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f23c1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040358744394619"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb71b7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.91      0.94       971\n",
      "        spam       0.58      0.90      0.71       144\n",
      "\n",
      "    accuracy                           0.90      1115\n",
      "   macro avg       0.78      0.90      0.82      1115\n",
      "weighted avg       0.93      0.90      0.91      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb877840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
